# KCPilot Configuration

# OpenAI API Configuration
OPENAI_API_KEY=your-openai-api-key-here

# Optional: Specify which model to use (defaults to gpt-4-turbo-preview)
# Valid models: gpt-4, gpt-4-turbo, gpt-4-turbo-preview, gpt-4o, gpt-4o-mini, gpt-3.5-turbo
# WARNING: gpt-5 does not exist yet! Use gpt-4-turbo-preview or gpt-4o instead.
# OPENAI_MODEL=gpt-4o

# Optional: OpenAI API Base URL (for custom endpoints or proxies)
# OPENAI_API_BASE=https://api.openai.com/v1

# Optional: Request timeout in seconds (default: 300)
# Increase this if you're getting timeout errors with large analyses
# LLM_REQUEST_TIMEOUT=300

# Optional: Max tokens for responses (default: 8000)
# Increase this if you're getting empty responses due to token limits
# LLM_MAX_TOKENS=8000

# Optional: Temperature for creativity (0.0-1.0, default: 0.3)
# Note: Newer models (GPT-4o, GPT-4-turbo) only support default temperature (1.0)
# LLM_TEMPERATURE=0.3

# Optional: Enable debug logging for LLM calls
# LLM_DEBUG=false
