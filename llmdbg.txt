[2025-08-22 15:50:27.106] --- LLM Response Received ---
[2025-08-22 15:50:27.106] Number of choices: 1
[2025-08-22 15:50:27.106] Tokens used - Prompt: 3356, Completion: 708, Total: 4064
[2025-08-22 15:50:27.106] 
--- Response Content ---
[2025-08-22 15:50:27.106] Response length: 3795 characters
[2025-08-22 15:50:27.106] Response preview (first 500 chars): From the Kafka logs you've provided, there are several issues and patterns that stand out, indicating that the Kafka brokers in your setup are experiencing connectivity and configuration problems. Here's a detailed analysis:

### Key Issues Identified:

1. **Repeated Service Stopping and Starting:**
   - All brokers show logs indicating that the Kafka service is repeatedly stopping and then starting within seconds. This repeated restarting could point to configuration issues, resource constraint...
[2025-08-22 15:50:27.106] 
--- Full Response ---
From the Kafka logs you've provided, there are several issues and patterns that stand out, indicating that the Kafka brokers in your setup are experiencing connectivity and configuration problems. Here's a detailed analysis:

### Key Issues Identified:

1. **Repeated Service Stopping and Starting:**
   - All brokers show logs indicating that the Kafka service is repeatedly stopping and then starting within seconds. This repeated restarting could point to configuration issues, resource constraints, or other failures that are causing Kafka to be unstable.

2. **Connection Failures:**
   - Multiple instances across different brokers (11, 12, 13, 15) log warnings that they are unable to establish connections with different broker nodes. This could be due to network partitioning, firewall issues, improper broker configurations (e.g., advertised listeners), or nodes that are actually down.

3. **Error in Broker Startup:**
   - Broker 13 experienced a fatal error related to a `NullPointerException`. The error trace indicates a problem within the Kafka server lifecycle, particularly with the RaftManager and the controller. This points towards internal configuration issues possibly related to the KRaft (Kafka Raft) controller setup or missing critical configurations.

4. **Metadata Log Issues:**
   - Broker 11 logs indicate that the QuorumController couldn't find metadata and is initializing from a bootstrap source. This can be normal when setting up a new cluster but could also suggest issues with existing metadata storage or inconsistency if not expected.

5. **Transient Errors in Partition Handling:**
   - There is also mention of `UNKNOWN_TOPIC_ID` errors when handling a specific partition (smltest-1), which could indicate transient issues if the partition was being created or deleted. Persistent presence of such errors points to potential cluster instability or metadata issues.

### Actionable Insights:

1. **Check Broker Configurations:**
   - Verify the configurations for each broker, paying particular attention to advertised listeners, network settings, and controller set up. Misconfigurations could easily lead to the issues observed.

2. **Investigate Network Connectivity:**
   - Employ network diagnostic tools to verify connectivity between brokers, ensuring that firewalls or security groups arenâ€™t blocking necessary ports like 9094. Network issues can greatly impact Kafka's ability to function effectively as a clustered service.

3. **Review Systemd Service Settings:**
   - The frequent restart of Kafka services might be due to systemd service settings or failure conditions. Check systemd configurations and logs for further insights on why these restarts are occurring.

4. **Address the Startup Error on Broker 13:**
   - Detailed investigation is needed on broker 13, especially regarding the mentioned `NullPointerException`. This likely indicates a deeper issue that may affect the stability and capability of your Kafka cluster.

5. **Monitor and Manage Resource Utilization:**
   - Ensure brokers have adequate resources (CPU, Memory) as evidenced by the memory peaks seen in logs. Consider resource monitoring and horizontal scaling if high usage is consistent.

6. **Consider Cluster Rebalancing or Maintenance:**
   - Given the raft of connection issues and unexpected service terminations, consider performing a controlled cluster maintenance or rebalancing to ensure service availability and reliability.

7. **Deploy Kafka Monitoring Tools:**
   - Use tools like Prometheus combined with Grafana, or specialized Kafka monitoring tools, to provide visual insights into the health and metrics of the Kafka cluster.

By systematically addressing these issues, you can increase the stability and performance of your Kafka installation.
[2025-08-22 15:50:27.106] 
==== END OF REQUEST/RESPONSE ====
[2025-08-22 15:50:27.106] Completed at: 2025-08-22 15:50:27

[2025-08-22 15:50:27.108] 
==== NEW LLM REQUEST ====
[2025-08-22 15:50:27.108] Timestamp: 2025-08-22 15:50:27
[2025-08-22 15:50:27.108] Model: gpt-4o
[2025-08-22 15:50:27.108] Max tokens: 16000
[2025-08-22 15:50:27.108] Number of messages: 2
[2025-08-22 15:50:27.108] --- Messages ---
[2025-08-22 15:50:27.108] 
[Message 1] Role: System
[2025-08-22 15:50:27.108] [Message 1] Content:
You are a Kafka performance tuning expert. Analyze configurations and metrics to provide optimization recommendations. Focus on practical, safe changes with clear justifications.
[2025-08-22 15:50:27.108] 
[Message 2] Role: User
[2025-08-22 15:50:27.108] [Message 2] Content:
Workload: General Kafka workload

Current Configuration:
{
  "broker_11/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_11/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_12/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_12/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_13/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_13/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_14/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_14/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_15/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_15/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_16/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_16/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n"
}

Metrics:
{
  "kafka_exporter": {
    "prometheus_metrics.txt": "# HELP go_gc_duration_seconds A summary of the wall-time pause (stop-the-world) duration in garbage collection cycles.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile=\"0\"} 2.566e-05\ngo_gc_duration_seconds{quantile=\"0.25\"} 3.67e-05\ngo_gc_duration_seconds{quantile=\"0.5\"} 7.015e-05\ngo_gc_duration_seconds{quantile=\"0.75\"} 0.000120631\ngo_gc_duration_seconds{quantile=\"1\"} 0.00074847\ngo_gc_duration_seconds_sum 0.003870445\ngo_gc_duration_seconds_count 36\n# HELP go_gc_gogc_percent Heap size target percentage configured by the user, otherwise 100. This value is set by the GOGC environment variable, and the runtime/debug.SetGCPercent function. Sourced from /gc/gogc:percent\n# TYPE go_gc_gogc_percent gauge\ngo_gc_gogc_percent 100\n# HELP go_gc_gomemlimit_bytes Go runtime memory limit configured by the user, otherwise math.MaxInt64. This value is set by the GOMEMLIMIT environment variable, and the runtime/debug.SetMemoryLimit function. Sourced from /gc/gomemlimit:bytes\n# TYPE go_gc_gomemlimit_bytes gauge\ngo_gc_gomemlimit_bytes 9.223372036854776e+18\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 17\n# HELP go_info Information about the Go environment.\n# TYPE go_info gauge\ngo_info{version=\"go1.24.0\"} 1\n# HELP go_memstats_alloc_bytes Number of bytes allocated in heap and currently in use. Equals to /memory/classes/heap/objects:bytes.\n# TYPE go_memstats_alloc_bytes gauge\ngo_memstats_alloc_bytes 3.139248e+06\n# HELP go_memstats_alloc_bytes_total Total number of bytes allocated in heap until now, even if released already. Equals to /gc/heap/allocs:bytes.\n# TYPE go_memstats_alloc_bytes_total counter\ngo_memstats_alloc_bytes_total 7.48948e+07\n# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table. Equals to /memory/classes/profiling/buckets:bytes.\n# TYPE go_memstats_buck_hash_sys_bytes gauge\ngo_memstats_buck_hash_sys_bytes 1.463981e+06\n# HELP go_memstats_frees_total Total number of heap objects frees. Equals to /gc/heap/frees:objects + /gc/heap/tiny/allocs:objects.\n# TYPE go_memstats_frees_total counter\ngo_memstats_frees_total 669311\n# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata. Equals to /memory/classes/metadata/other:bytes.\n# TYPE go_memstats_gc_sys_bytes gauge\ngo_memstats_gc_sys_bytes 2.990968e+06\n# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and currently in use, same as go_memstats_alloc_bytes. Equals to /memory/classes/heap/objects:bytes.\n# TYPE go_memstats_heap_alloc_bytes gauge\ngo_memstats_heap_alloc_bytes 3.139248e+06\n# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used. Equals to /memory/classes/heap/released:bytes + /memory/classes/heap/free:bytes.\n# TYPE go_memstats_heap_idle_bytes gauge\ngo_memstats_heap_idle_bytes 7.094272e+06\n# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use. Equals to /memory/classes/heap/objects:bytes + /memory/classes/heap/unused:bytes\n# TYPE go_memstats_heap_inuse_bytes gauge\ngo_memstats_heap_inuse_bytes 4.767744e+06\n# HELP go_memstats_heap_objects Number of currently allocated objects. Equals to /gc/heap/objects:objects.\n# TYPE go_memstats_heap_objects gauge\ngo_memstats_heap_objects 9752\n# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS. Equals to /memory/classes/heap/released:bytes.\n# TYPE go_memstats_heap_released_bytes gauge\ngo_memstats_heap_released_bytes 5.431296e+06\n# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system. Equals to /memory/classes/heap/objects:bytes + /memory/classes/heap/unused:bytes + /memory/classes/heap/released:bytes + /memory/classes/heap/free:bytes.\n# TYPE go_memstats_heap_sys_bytes gauge\ngo_memstats_heap_sys_bytes 1.1862016e+07\n# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.\n# TYPE go_memstats_last_gc_time_seconds gauge\ngo_memstats_last_gc_time_seconds 1.7556766012420785e+09\n# HELP go_memstats_mallocs_total Total number of heap objects allocated, both live and gc-ed. Semantically a counter version for go_memstats_heap_objects gauge. Equals to /gc/heap/allocs:objects + /gc/heap/tiny/allocs:objects.\n# TYPE go_memstats_mallocs_total counter\ngo_memstats_mallocs_total 679063\n# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures. Equals to /memory/classes/metadata/mcache/inuse:bytes.\n# TYPE go_memstats_mcache_inuse_bytes gauge\ngo_memstats_mcache_inuse_bytes 2416\n# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system. Equals to /memory/classes/metadata/mcache/inuse:bytes + /memory/classes/metadata/mcache/free:bytes.\n# TYPE go_memstats_mcache_sys_bytes gauge\ngo_memstats_mcache_sys_bytes 15704\n# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures. Equals to /memory/classes/metadata/mspan/inuse:bytes.\n# TYPE go_memstats_mspan_inuse_bytes gauge\ngo_memstats_mspan_inuse_bytes 74400\n# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system. Equals to /memory/classes/metadata/mspan/inuse:bytes + /memory/classes/metadata/mspan/free:bytes.\n# TYPE go_memstats_mspan_sys_bytes gauge\ngo_memstats_mspan_sys_bytes 97920\n# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place. Equals to /gc/heap/goal:bytes.\n# TYPE go_memstats_next_gc_bytes gauge\ngo_memstats_next_gc_bytes 5.571218e+06\n# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations. Equals to /memory/classes/other:bytes.\n# TYPE go_memstats_other_sys_bytes gauge\ngo_memstats_other_sys_bytes 499467\n# HELP go_memstats_stack_inuse_bytes Number of bytes obtained from system for stack allocator in non-CGO environments. Equals to /memory/classes/heap/stacks:bytes.\n# TYPE go_memstats_stack_inuse_bytes gauge\ngo_memstats_stack_inuse_bytes 720896\n# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator. Equals to /memory/classes/heap/stacks:bytes + /memory/classes/os-stacks:bytes.\n# TYPE go_memstats_stack_sys_bytes gauge\ngo_memstats_stack_sys_bytes 720896\n# HELP go_memstats_sys_bytes Number of bytes obtained from system. Equals to /memory/classes/total:byte.\n# TYPE go_memstats_sys_bytes gauge\ngo_memstats_sys_bytes 1.7650952e+07\n# HELP go_sched_gomaxprocs_threads The current runtime.GOMAXPROCS setting, or the number of operating system threads that can execute user-level Go code simultaneously. Sourced from /sched/gomaxprocs:threads\n# TYPE go_sched_gomaxprocs_threads gauge\ngo_sched_gomaxprocs_threads 2\n# HELP go_threads Number of OS threads created.\n# TYPE go_threads gauge\ngo_threads 5\n# HELP kafka_broker_info Information about the Kafka Broker.\n# TYPE kafka_broker_info gauge\nkafka_broker_info{address=\"kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal:9092\",id=\"11\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal:9092\",id=\"12\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal:9092\",id=\"13\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc2-2.c.bartek-rekke-sandbox.internal:9092\",id=\"14\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal:9092\",id=\"15\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc3-2.c.bartek-rekke-sandbox.internal:9092\",id=\"16\"} 1\n# HELP kafka_brokers Number of Brokers in the Kafka Cluster.\n# TYPE kafka_brokers gauge\nkafka_brokers 6\n# HELP kafka_exporter_build_info A metric with a constant '1' value labeled by version, revision, branch, goversion from which kafka_exporter was built, and the goos and goarch for the build.\n# TYPE kafka_exporter_build_info gauge\nkafka_exporter_build_info{branch=\"HEAD\",goarch=\"amd64\",goos=\"linux\",goversion=\"go1.24.0\",revision=\"8ec24078707d4d3b349e71522ebd7f179746072d\",tags=\"netgo\",version=\"1.9.0\"} 1\n# HELP kafka_topic_partition_current_offset Current Offset of a Broker at Topic/Partition\n# TYPE kafka_topic_partition_current_offset gauge\nkafka_topic_partition_current_offset{partition=\"0\",topic=\"smltest\"} 1\nkafka_topic_partition_current_offset{partition=\"1\",topic=\"smltest\"} 1\nkafka_topic_partition_current_offset{partition=\"2\",topic=\"smltest\"} 0\nkafka_topic_partition_current_offset{partition=\"3\",topic=\"smltest\"} 1\nkafka_topic_partition_current_offset{partition=\"4\",topic=\"smltest\"} 0\nkafka_topic_partition_current_offset{partition=\"5\",topic=\"smltest\"} 0\n# HELP kafka_topic_partition_in_sync_replica Number of In-Sync Replicas for this Topic/Partition\n# TYPE kafka_topic_partition_in_sync_replica gauge\nkafka_topic_partition_in_sync_replica{partition=\"0\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"1\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"2\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"3\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"4\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"5\",topic=\"smltest\"} 2\n# HELP kafka_topic_partition_leader Leader Broker ID of this Topic/Partition\n# TYPE kafka_topic_partition_leader gauge\nkafka_topic_partition_leader{partition=\"0\",topic=\"smltest\"} 15\nkafka_topic_partition_leader{partition=\"1\",topic=\"smltest\"} 16\nkafka_topic_partition_leader{partition=\"2\",topic=\"smltest\"} 11\nkafka_topic_partition_leader{partition=\"3\",topic=\"smltest\"} 12\nkafka_topic_partition_leader{partition=\"4\",topic=\"smltest\"} 13\nkafka_topic_partition_leader{partition=\"5\",topic=\"smltest\"} 14\n# HELP kafka_topic_partition_leader_is_preferred 1 if Topic/Partition is using the Preferred Broker\n# TYPE kafka_topic_partition_leader_is_preferred gauge\nkafka_topic_partition_leader_is_preferred{partition=\"0\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"1\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"2\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"3\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"4\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"5\",topic=\"smltest\"} 1\n# HELP kafka_topic_partition_oldest_offset Oldest Offset of a Broker at Topic/Partition\n# TYPE kafka_topic_partition_oldest_offset gauge\nkafka_topic_partition_oldest_offset{partition=\"0\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"1\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"2\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"3\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"4\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"5\",topic=\"smltest\"} 0\n# HELP kafka_topic_partition_replicas Number of Replicas for this Topic/Partition\n# TYPE kafka_topic_partition_replicas gauge\nkafka_topic_partition_replicas{partition=\"0\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"1\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"2\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"3\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"4\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"5\",topic=\"smltest\"} 2\n# HELP kafka_topic_partition_under_replicated_partition 1 if Topic/Partition is under Replicated\n# TYPE kafka_topic_partition_under_replicated_partition gauge\nkafka_topic_partition_under_replicated_partition{partition=\"0\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"1\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"2\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"3\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"4\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"5\",topic=\"smltest\"} 0\n# HELP kafka_topic_partitions Number of partitions for this Topic\n# TYPE kafka_topic_partitions gauge\nkafka_topic_partitions{topic=\"smltest\"} 6\n# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.\n# TYPE process_cpu_seconds_total counter\nprocess_cpu_seconds_total 1.51\n# HELP process_max_fds Maximum number of open file descriptors.\n# TYPE process_max_fds gauge\nprocess_max_fds 524287\n# HELP process_network_receive_bytes_total Number of bytes received by the process over the network.\n# TYPE process_network_receive_bytes_total counter\nprocess_network_receive_bytes_total 2.31658703e+08\n# HELP process_network_transmit_bytes_total Number of bytes sent by the process over the network.\n# TYPE process_network_transmit_bytes_total counter\nprocess_network_transmit_bytes_total 6.045448e+07\n# HELP process_open_fds Number of open file descriptors.\n# TYPE process_open_fds gauge\nprocess_open_fds 11\n# HELP process_resident_memory_bytes Resident memory size in bytes.\n# TYPE process_resident_memory_bytes gauge\nprocess_resident_memory_bytes 2.3236608e+07\n# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.\n# TYPE process_start_time_seconds gauge\nprocess_start_time_seconds 1.75567555438e+09\n# HELP process_virtual_memory_bytes Virtual memory size in bytes.\n# TYPE process_virtual_memory_bytes gauge\nprocess_virtual_memory_bytes 1.273516032e+09\n# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.\n# TYPE process_virtual_memory_max_bytes gauge\nprocess_virtual_memory_max_bytes 1.8446744073709552e+19\n# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.\n# TYPE promhttp_metric_handler_requests_in_flight gauge\npromhttp_metric_handler_requests_in_flight 1\n# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.\n# TYPE promhttp_metric_handler_requests_total counter\npromhttp_metric_handler_requests_total{code=\"200\"} 207\npromhttp_metric_handler_requests_total{code=\"500\"} 0\npromhttp_metric_handler_requests_total{code=\"503\"} 0\n"
  }
}
[2025-08-22 15:50:27.108] 
--- End of Messages ---
[2025-08-22 15:50:27.108] Sending request to LLM API (timeout: 300 seconds)...
[2025-08-22 15:50:58.833] --- LLM Response Received ---
[2025-08-22 15:50:58.833] Number of choices: 1
[2025-08-22 15:50:58.833] Tokens used - Prompt: 14239, Completion: 810, Total: 15049
[2025-08-22 15:50:58.833] 
--- Response Content ---
[2025-08-22 15:50:58.833] Response length: 3901 characters
[2025-08-22 15:50:58.833] Response preview (first 500 chars): Analyzing the provided configuration and metrics, here are some recommendations for tuning your Kafka setup for improved performance and reliability:

### Broker Configuration:
1. **Unique `broker.id`:**
   - Currently, all brokers have the `broker.id=0`. Each broker should have a unique `broker.id` for proper identification within the cluster. Ensure that each broker in your cluster is assigned a unique integer id. For example, broker 11 can have `broker.id=11`, broker 12 can have `broker.id=12...
[2025-08-22 15:50:58.833] 
--- Full Response ---
Analyzing the provided configuration and metrics, here are some recommendations for tuning your Kafka setup for improved performance and reliability:

### Broker Configuration:
1. **Unique `broker.id`:**
   - Currently, all brokers have the `broker.id=0`. Each broker should have a unique `broker.id` for proper identification within the cluster. Ensure that each broker in your cluster is assigned a unique integer id. For example, broker 11 can have `broker.id=11`, broker 12 can have `broker.id=12`, etc.

2. **Replication Factor:**
   - Your configuration shows a replication factor of 1 for internal topics like `__consumer_offsets` and `__transaction_state`. This setting is risky for production as data loss is possible if a broker fails. It is recommended to increase the replication factor to at least 3 for better redundancy and fault tolerance.

3. **Log Directories:**
   - The log directory for all brokers is set to `/tmp/kafka-logs`, which is not ideal for persistent storage and is prone to being cleaned up automatically on server reboots. Configure `log.dirs` to point to a dedicated mount point with sufficient storage and IOPS.

4. **Number of Partitions:**
   - The default `num.partitions=1` can limit the parallelism and scalability of Kafka topics. Increasing the number of partitions can help distribute the load across multiple brokers. The optimal number depends on your workload, but typically starting with at least 3 or more partitions is beneficial.

5. **Listener Configurations:**
   - Ensure that both the `listeners` and `advertised.listeners` are properly configured. This is critical if clients are connecting from different networks or if you are using DNS names instead of IP addresses.

### Performance Tuning:
1. **Network Threads:**
   - `num.network.threads=3` may be undersized if your workload consists of a large number of simultaneous requests. Consider increasing this based on your network capacity (typically up to 8 is considered but depends on the server's CPU and network capacity).

2. **I/O Threads:**
   - `num.io.threads=8` is generally okay for a moderate throughput workload. However, if disk I/O becomes a bottleneck (especially if you have high throughput topics), increasing the number of I/O threads can help. Typically, matching the number of threads to the number of CPU cores is a good starting point.

3. **Socket Buffer Sizes:**
   - Both `socket.send.buffer.bytes` and `socket.receive.buffer.bytes` are set to 102400 bytes. If there are network latency issues or packet drops, consider increasing these values to between 512 KB to 1 MB to improve data flow efficiency.

4. **Log Segment Size:**
   - Ensure `log.segment.bytes` is tuned to balance between disk usage and performance. Smaller segments are easier to manage and recover but might reduce throughput. A setting like 1 GB is often a good balance, but this can be adjusted based on the usage pattern.

### Metrics and Observations:
1. **GC Metrics:**
   - The Go GC (Garbage Collector) metrics do not indicate any immediate concerns regarding pause times (`go_gc_duration_seconds`) or memory exhaustion. Continue to monitor these metrics to ensure garbage collection does not impact performance.

2. **Partition and Replication:**
   - Review the `kafka_topic_partition_replicas` metrics and consider increasing the number of replicas if higher availability and fault tolerance are needed. All partitions have a replication factor of 2, an upgrade to 3 would provide enhanced safety against data loss.

3. **Under-Replicated Partitions:**
   - Monitor the `kafka_topic_partition_under_replicated_partition` metric to immediately catch any partitions that fall out of sync, impacting fault tolerance.

Implement these changes gradually, monitoring the impact they have on your system's performance and stability, and consider rollback strategies to mitigate potential risks.
[2025-08-22 15:50:58.833] 
==== END OF REQUEST/RESPONSE ====
[2025-08-22 15:50:58.833] Completed at: 2025-08-22 15:50:58

[2025-08-22 15:54:57.629] ==================================================
[2025-08-22 15:54:57.629] === LLM Debug Logging Session Started ===
[2025-08-22 15:54:57.629] ==================================================
[2025-08-22 15:54:57.629] Model: gpt-4o
[2025-08-22 15:54:57.629] Max Tokens: 16000
[2025-08-22 15:54:57.629] Temperature: 0.3
[2025-08-22 15:54:57.629] Timeout: 300 seconds
[2025-08-22 15:54:57.629] ==================================================

[2025-08-22 15:54:57.630] 
==== NEW LLM REQUEST ====
[2025-08-22 15:54:57.630] Timestamp: 2025-08-22 15:54:57
[2025-08-22 15:54:57.630] Model: gpt-4o
[2025-08-22 15:54:57.630] Max tokens: 16000
[2025-08-22 15:54:57.630] Number of messages: 2
[2025-08-22 15:54:57.630] --- Messages ---
[2025-08-22 15:54:57.630] 
[Message 1] Role: System
[2025-08-22 15:54:57.630] [Message 1] Content:
You are an expert Kafka administrator analyzing Kafka logs. Identify issues, patterns, and provide actionable insights.
[2025-08-22 15:54:57.630] 
[Message 2] Role: User
[2025-08-22 15:54:57.630] [Message 2] Content:
Context: Kafka broker logs

Please analyze these Kafka logs:
{
  "broker_11/journald.log": "Aug 20 07:37:43 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\nAug 20 07:37:45 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal systemd[1]: Stopping kafka.service - Kafka server...\nAug 20 07:37:45 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal systemd[1]: kafka.service: Deactivated successfully.\nAug 20 07:37:45 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal systemd[1]: Stopped kafka.service - Kafka server.\nAug 20 07:37:45 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal systemd[1]: kafka.service: Consumed 2.113s CPU time, 187.4M memory peak, 0B memory swap peak.\nAug 20 07:37:45 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\nAug 20 07:37:47 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal kafka[3885]: [2025-08-20 07:37:47,217] WARN [RaftManager id=11] Connection to node 11 (kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal/10.0.10.2:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:49 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal kafka[3885]: [2025-08-20 07:37:49,237] WARN [RaftManager id=11] Connection to node 15 (kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal/10.0.30.3:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:49 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal kafka[3885]: [2025-08-20 07:37:49,238] WARN [RaftManager id=11] Connection to node 13 (kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal/10.0.20.2:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:50 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal kafka[3885]: [2025-08-20 07:37:50,237] WARN [RaftManager id=11] Connection to node 15 (kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal/10.0.30.3:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:50 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal kafka[3885]: [2025-08-20 07:37:50,237] WARN [RaftManager id=11] Connection to node 13 (kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal/10.0.20.2:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:50 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal kafka[3885]: [2025-08-20 07:37:50,561] WARN [QuorumController id=11] Performing controller activation. The metadata log appears to be empty. Appending 1 bootstrap record(s) in metadata transaction at metadata.version 3.9-IV0 from bootstrap source 'the binary bootstrap metadata file: /data/kafka/generic/bootstrap.checkpoint'. Setting the ZK migration state to NONE since this is a de-novo KRaft cluster. (org.apache.kafka.controller.QuorumController)\nAug 20 07:38:16 kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal kafka[3885]: [2025-08-20 07:38:16,984] WARN [ReplicaFetcher replicaId=11, leaderId=16, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition smltest-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)\n",
  "broker_12/journald.log": "Aug 20 07:37:43 kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\nAug 20 07:37:45 kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal systemd[1]: Stopping kafka.service - Kafka server...\nAug 20 07:37:45 kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal systemd[1]: kafka.service: Deactivated successfully.\nAug 20 07:37:45 kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal systemd[1]: Stopped kafka.service - Kafka server.\nAug 20 07:37:45 kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal systemd[1]: kafka.service: Consumed 2.416s CPU time, 223.8M memory peak, 0B memory swap peak.\nAug 20 07:37:45 kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\nAug 20 07:37:47 kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal kafka[3828]: [2025-08-20 07:37:47,057] WARN [RaftManager id=12] Connection to node 11 (kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal/10.0.10.2:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:47 kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal kafka[3828]: [2025-08-20 07:37:47,189] WARN [RaftManager id=12] Connection to node 11 (kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal/10.0.10.2:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
  "broker_13/journald.log": "Aug 20 07:37:43 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\nAug 20 07:37:45 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal systemd[1]: Stopping kafka.service - Kafka server...\nAug 20 07:37:45 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]: [2025-08-20 07:37:45,700] WARN [RaftManager id=13] Connection to node 11 (kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal/10.0.10.2:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]: [2025-08-20 07:37:48,284] WARN [NodeToControllerChannelManager id=13 name=registration] Attempting to close NetworkClient that has already been closed. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]: [2025-08-20 07:37:48,308] ERROR [BrokerServer id=13] Fatal error during broker startup. Prepare to shutdown (kafka.server.BrokerServer)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]: java.lang.NullPointerException: Cannot invoke \"kafka.raft.RaftManager.leaderAndEpoch()\" because the return value of \"kafka.server.RaftControllerNodeProvider.raftManager()\" is null\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.server.RaftControllerNodeProvider.getControllerInfo(NodeToControllerChannelManager.scala:118)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.server.NodeToControllerChannelManagerImpl.newRequestThread(NodeToControllerChannelManager.scala:200)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.server.NodeToControllerChannelManagerImpl.<init>(NodeToControllerChannelManager.scala:141)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.server.BrokerServer.startup(BrokerServer.scala:234)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.server.KafkaRaftServer.$anonfun$startup$2(KafkaRaftServer.scala:99)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.server.KafkaRaftServer.$anonfun$startup$2$adapted(KafkaRaftServer.scala:99)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at scala.Option.foreach(Option.scala:437)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.server.KafkaRaftServer.startup(KafkaRaftServer.scala:99)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.Kafka$.main(Kafka.scala:112)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal kafka[3466]:         at kafka.Kafka.main(Kafka.scala)\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal systemd[1]: kafka.service: Deactivated successfully.\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal systemd[1]: Stopped kafka.service - Kafka server.\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal systemd[1]: kafka.service: Consumed 4.383s CPU time, 217.3M memory peak, 0B memory swap peak.\nAug 20 07:37:48 kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\n",
  "broker_14/journald.log": "Aug 20 07:37:43 kafka-poligon-dc2-2.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\nAug 20 07:37:45 kafka-poligon-dc2-2.c.bartek-rekke-sandbox.internal systemd[1]: Stopping kafka.service - Kafka server...\nAug 20 07:37:45 kafka-poligon-dc2-2.c.bartek-rekke-sandbox.internal systemd[1]: kafka.service: Deactivated successfully.\nAug 20 07:37:45 kafka-poligon-dc2-2.c.bartek-rekke-sandbox.internal systemd[1]: Stopped kafka.service - Kafka server.\nAug 20 07:37:45 kafka-poligon-dc2-2.c.bartek-rekke-sandbox.internal systemd[1]: kafka.service: Consumed 2.132s CPU time, 117.4M memory peak, 0B memory swap peak.\nAug 20 07:37:45 kafka-poligon-dc2-2.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\n",
  "broker_15/journald.log": "Aug 20 07:37:43 kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal systemd[1]: Started kafka.service - Kafka server.\nAug 20 07:37:45 kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal systemd[1]: Stopping kafka.service - Kafka server...\nAug 20 07:37:45 kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal kafka[3479]: [2025-08-20 07:37:45,297] WARN [RaftManager id=15] Connection to node 15 (kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal/10.0.30.3:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:45 kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal kafka[3479]: [2025-08-20 07:37:45,314] WARN [RaftManager id=15] Connection to node 13 (kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal/10.0.20.2:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\nAug 20 07:37:45 kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal kafka[3... [truncated]
[2025-08-22 15:54:57.630] 
--- End of Messages ---
[2025-08-22 15:54:57.631] Sending request to LLM API (timeout: 300 seconds)...
[2025-08-22 15:55:13.027] --- LLM Response Received ---
[2025-08-22 15:55:13.027] Number of choices: 1
[2025-08-22 15:55:13.027] Tokens used - Prompt: 3356, Completion: 559, Total: 3915
[2025-08-22 15:55:13.027] 
--- Response Content ---
[2025-08-22 15:55:13.027] Response length: 2979 characters
[2025-08-22 15:55:13.027] Response preview (first 500 chars): The Kafka logs you provided contain multiple warnings and errors across different broker nodes, indicating some systemic issues within the cluster. Let's break down the main points and provide actionable insights:

### Broad Observations:

1. **Frequent Restarts and Network Issues:**
   - All brokers appear to be starting and stopping Kafka services frequently within a very short time interval, which is unusual.
   - There are multiple warnings about the inability to establish connections betwee...
[2025-08-22 15:55:13.027] 
--- Full Response ---
The Kafka logs you provided contain multiple warnings and errors across different broker nodes, indicating some systemic issues within the cluster. Let's break down the main points and provide actionable insights:

### Broad Observations:

1. **Frequent Restarts and Network Issues:**
   - All brokers appear to be starting and stopping Kafka services frequently within a very short time interval, which is unusual.
   - There are multiple warnings about the inability to establish connections between nodes, suggesting possible network issues or misconfiguration.

2. **System-Specific Errors:**
   - **Broker 11**: 
     - Logs contain warnings about connection failures to other Kafka nodes and issues with metadata log initialization, indicating potential network issues or a malfunction in the cluster's controller mechanics.
   - **Broker 12**: 
     - Similar network connectivity warnings.
   - **Broker 13**:
     - Encountered a fatal error during startup due to a `NullPointerException`, likely related to issues in the RaftManager setup, indicating a problem initializing the Raft protocol.
   - **Broker 14 and 15**:
     - Experience the same pattern of network connectivity issues.

3. **KRaft Cluster Initialization Issues:**
   - The messages regarding the lack of metadata log in a Quorum Controller activation might suggest the cluster isn't initializing correctly as a KRaft cluster, which uses Raft consensus instead of Zookeeper.

### Actionable Insights:

1. **Network Diagnostics:**
   - Start by diagnosing network connectivity between nodes. Check firewalls, security groups, or any underlying network issues that might impede node communication.

2. **Configuration Verification:**
   - Verify configuration files for each broker to ensure all have consistent and correct settings, particularly focusing on advertised listeners and inter-broker protocols.

3. **Examine Raft and KRaft Initialization:**
   - Investigate the setup of the Raft Manager and verify that the configuration aligns with KRaft requirements. Ensure that each node correctly identifies its role and participates in the same quorum.

4. **Review Recent Changes or Deployments:**
   - Examine if recent changes or deployments might coincide with these issues. Rollback if necessary or adjust configurations based on best practices and initial setups.

5. **Error Handling and Stability Checks:**
   - Enhance error handling mechanisms, increasing visibility into why restarts are happening, and stabilize the cluster by ensuring minimum overlaps between start and stop cycles, possibly introducing throttling.

6. **Software Version Compatibility:**
   - Make sure that all components of the Kafka system, including client libraries, brokers, and Kafka tools, are on compatible versions.

If issues continue after these steps, consider engaging with Kafka's support channels or communities for further assistance, providing detailed logs and descriptions of current configurations.
[2025-08-22 15:55:13.027] 
==== END OF REQUEST/RESPONSE ====
[2025-08-22 15:55:13.027] Completed at: 2025-08-22 15:55:13

[2025-08-22 15:55:13.029] 
==== NEW LLM REQUEST ====
[2025-08-22 15:55:13.029] Timestamp: 2025-08-22 15:55:13
[2025-08-22 15:55:13.029] Model: gpt-4o
[2025-08-22 15:55:13.029] Max tokens: 16000
[2025-08-22 15:55:13.029] Number of messages: 2
[2025-08-22 15:55:13.029] --- Messages ---
[2025-08-22 15:55:13.029] 
[Message 1] Role: System
[2025-08-22 15:55:13.029] [Message 1] Content:
You are a Kafka performance tuning expert. Analyze configurations and metrics to provide optimization recommendations. Focus on practical, safe changes with clear justifications.
[2025-08-22 15:55:13.029] 
[Message 2] Role: User
[2025-08-22 15:55:13.029] [Message 2] Content:
Workload: General Kafka workload

Current Configuration:
{
  "broker_11/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_11/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_12/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_12/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_13/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_13/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_14/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_14/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_15/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_15/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n",
  "broker_16/kafka.service": "[Unit]\nDescription=Kafka server\nAfter=network.target\n\n[Service]\nType=simple\nUser=kafka\nGroup=kafka\nExecStart=/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties\nRestart=on-failure\nLimitNOFILE=64000\nSuccessExitStatus=143\nSyslogIdentifier=kafka\nEnvironmentFile=/etc/default/kafka\n\n\n[Install]\nWantedBy=multi-user.target\n",
  "broker_16/server.properties": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.\n# See kafka.server.KafkaConfig for additional details and defaults\n#\n\n############################# Server Basics #############################\n\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=0\n\n############################# Socket Server Settings #############################\n\n# The address the socket server listens on. If not configured, the host name will be equal to the value of\n# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.\n#   FORMAT:\n#     listeners = listener_name://host_name:port\n#   EXAMPLE:\n#     listeners = PLAINTEXT://your.host.name:9092\n#listeners=PLAINTEXT://:9092\n\n# Listener name, hostname and port the broker will advertise to clients.\n# If not set, it uses the value for \"listeners\".\n#advertised.listeners=PLAINTEXT://your.host.name:9092\n\n# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details\n#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL\n\n# The number of threads that the server uses for receiving requests from the network and sending responses to the network\nnum.network.threads=3\n\n# The number of threads that the server uses for processing requests, which may include disk I/O\nnum.io.threads=8\n\n# The send buffer (SO_SNDBUF) used by the socket server\nsocket.send.buffer.bytes=102400\n\n# The receive buffer (SO_RCVBUF) used by the socket server\nsocket.receive.buffer.bytes=102400\n\n# The maximum size of a request that the socket server will accept (protection against OOM)\nsocket.request.max.bytes=104857600\n\n\n############################# Log Basics #############################\n\n# A comma separated list of directories under which to store log files\nlog.dirs=/tmp/kafka-logs\n\n# The default number of log partitions per topic. More partitions allow greater\n# parallelism for consumption, but this will also result in more files across\n# the brokers.\nnum.partitions=1\n\n# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.\n# This value is recommended to be increased for installations with data dirs located in RAID array.\nnum.recovery.threads.per.data.dir=1\n\n############################# Internal Topic Settings  #############################\n# The replication factor for the group metadata internal topics \"__consumer_offsets\" and \"__transaction_state\"\n# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.\noffsets.topic.replication.factor=1\ntransaction.state.log.replication.factor=1\ntransaction.state.log.min.isr=1\n\n############################# Log Flush Policy #############################\n\n# Messages are immediately written to the filesystem but by default we only fsync() to sync\n# the OS cache lazily. The following configurations control the flush of data to disk.\n# There are a few important trade-offs here:\n#    1. Durability: Unflushed data may be lost if you are not using replication.\n#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.\n#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.\n# The settings below allow one to configure the flush policy to flush data after a period of time or\n# every N messages (or both). This can be done globally and overridden on a per-topic basis.\n\n# The number of messages to accept before forcing a flush of data to disk\n#log.flush.interval.messages=10000\n\n# The maximum amount of time a message can sit in a log before we force a flush\n#log.flush.interval.ms=1000\n\n############################# Log Retention Policy #############################\n\n# The following configurations control the disposal of log segments. The policy can\n# be set to delete segments after a period of time, or after a given size has accumulated.\n# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens\n# from the end of the log.\n\n# The minimum age of a log file to be eligible for deletion due to age\nlog.retention.hours=168\n\n# A size-based retention policy for logs. Segments are pruned from the log unless the remaining\n# segments drop below log.retention.bytes. Functions independently of log.retention.hours.\n#log.retention.bytes=1073741824\n\n# The maximum size of a log segment file. When this size is reached a new log segment will be created.\n#log.segment.bytes=1073741824\n\n# The interval at which log segments are checked to see if they can be deleted according\n# to the retention policies\nlog.retention.check.interval.ms=300000\n\n############################# Zookeeper #############################\n\n# Zookeeper connection string (see zookeeper docs for details).\n# This is a comma separated host:port pairs, each corresponding to a zk\n# server. e.g. \"127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\".\n# You can also append an optional chroot string to the urls to specify the\n# root directory for all kafka znodes.\nzookeeper.connect=localhost:2181\n\n# Timeout in ms for connecting to zookeeper\nzookeeper.connection.timeout.ms=18000\n\n\n############################# Group Coordinator Settings #############################\n\n# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.\n# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.\n# The default value for this is 3 seconds.\n# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.\n# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.\ngroup.initial.rebalance.delay.ms=0\n"
}

Metrics:
{
  "kafka_exporter": {
    "prometheus_metrics.txt": "# HELP go_gc_duration_seconds A summary of the wall-time pause (stop-the-world) duration in garbage collection cycles.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile=\"0\"} 2.566e-05\ngo_gc_duration_seconds{quantile=\"0.25\"} 3.67e-05\ngo_gc_duration_seconds{quantile=\"0.5\"} 7.015e-05\ngo_gc_duration_seconds{quantile=\"0.75\"} 0.000120631\ngo_gc_duration_seconds{quantile=\"1\"} 0.00074847\ngo_gc_duration_seconds_sum 0.003870445\ngo_gc_duration_seconds_count 36\n# HELP go_gc_gogc_percent Heap size target percentage configured by the user, otherwise 100. This value is set by the GOGC environment variable, and the runtime/debug.SetGCPercent function. Sourced from /gc/gogc:percent\n# TYPE go_gc_gogc_percent gauge\ngo_gc_gogc_percent 100\n# HELP go_gc_gomemlimit_bytes Go runtime memory limit configured by the user, otherwise math.MaxInt64. This value is set by the GOMEMLIMIT environment variable, and the runtime/debug.SetMemoryLimit function. Sourced from /gc/gomemlimit:bytes\n# TYPE go_gc_gomemlimit_bytes gauge\ngo_gc_gomemlimit_bytes 9.223372036854776e+18\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 17\n# HELP go_info Information about the Go environment.\n# TYPE go_info gauge\ngo_info{version=\"go1.24.0\"} 1\n# HELP go_memstats_alloc_bytes Number of bytes allocated in heap and currently in use. Equals to /memory/classes/heap/objects:bytes.\n# TYPE go_memstats_alloc_bytes gauge\ngo_memstats_alloc_bytes 3.139248e+06\n# HELP go_memstats_alloc_bytes_total Total number of bytes allocated in heap until now, even if released already. Equals to /gc/heap/allocs:bytes.\n# TYPE go_memstats_alloc_bytes_total counter\ngo_memstats_alloc_bytes_total 7.48948e+07\n# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table. Equals to /memory/classes/profiling/buckets:bytes.\n# TYPE go_memstats_buck_hash_sys_bytes gauge\ngo_memstats_buck_hash_sys_bytes 1.463981e+06\n# HELP go_memstats_frees_total Total number of heap objects frees. Equals to /gc/heap/frees:objects + /gc/heap/tiny/allocs:objects.\n# TYPE go_memstats_frees_total counter\ngo_memstats_frees_total 669311\n# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata. Equals to /memory/classes/metadata/other:bytes.\n# TYPE go_memstats_gc_sys_bytes gauge\ngo_memstats_gc_sys_bytes 2.990968e+06\n# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and currently in use, same as go_memstats_alloc_bytes. Equals to /memory/classes/heap/objects:bytes.\n# TYPE go_memstats_heap_alloc_bytes gauge\ngo_memstats_heap_alloc_bytes 3.139248e+06\n# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used. Equals to /memory/classes/heap/released:bytes + /memory/classes/heap/free:bytes.\n# TYPE go_memstats_heap_idle_bytes gauge\ngo_memstats_heap_idle_bytes 7.094272e+06\n# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use. Equals to /memory/classes/heap/objects:bytes + /memory/classes/heap/unused:bytes\n# TYPE go_memstats_heap_inuse_bytes gauge\ngo_memstats_heap_inuse_bytes 4.767744e+06\n# HELP go_memstats_heap_objects Number of currently allocated objects. Equals to /gc/heap/objects:objects.\n# TYPE go_memstats_heap_objects gauge\ngo_memstats_heap_objects 9752\n# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS. Equals to /memory/classes/heap/released:bytes.\n# TYPE go_memstats_heap_released_bytes gauge\ngo_memstats_heap_released_bytes 5.431296e+06\n# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system. Equals to /memory/classes/heap/objects:bytes + /memory/classes/heap/unused:bytes + /memory/classes/heap/released:bytes + /memory/classes/heap/free:bytes.\n# TYPE go_memstats_heap_sys_bytes gauge\ngo_memstats_heap_sys_bytes 1.1862016e+07\n# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.\n# TYPE go_memstats_last_gc_time_seconds gauge\ngo_memstats_last_gc_time_seconds 1.7556766012420785e+09\n# HELP go_memstats_mallocs_total Total number of heap objects allocated, both live and gc-ed. Semantically a counter version for go_memstats_heap_objects gauge. Equals to /gc/heap/allocs:objects + /gc/heap/tiny/allocs:objects.\n# TYPE go_memstats_mallocs_total counter\ngo_memstats_mallocs_total 679063\n# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures. Equals to /memory/classes/metadata/mcache/inuse:bytes.\n# TYPE go_memstats_mcache_inuse_bytes gauge\ngo_memstats_mcache_inuse_bytes 2416\n# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system. Equals to /memory/classes/metadata/mcache/inuse:bytes + /memory/classes/metadata/mcache/free:bytes.\n# TYPE go_memstats_mcache_sys_bytes gauge\ngo_memstats_mcache_sys_bytes 15704\n# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures. Equals to /memory/classes/metadata/mspan/inuse:bytes.\n# TYPE go_memstats_mspan_inuse_bytes gauge\ngo_memstats_mspan_inuse_bytes 74400\n# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system. Equals to /memory/classes/metadata/mspan/inuse:bytes + /memory/classes/metadata/mspan/free:bytes.\n# TYPE go_memstats_mspan_sys_bytes gauge\ngo_memstats_mspan_sys_bytes 97920\n# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place. Equals to /gc/heap/goal:bytes.\n# TYPE go_memstats_next_gc_bytes gauge\ngo_memstats_next_gc_bytes 5.571218e+06\n# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations. Equals to /memory/classes/other:bytes.\n# TYPE go_memstats_other_sys_bytes gauge\ngo_memstats_other_sys_bytes 499467\n# HELP go_memstats_stack_inuse_bytes Number of bytes obtained from system for stack allocator in non-CGO environments. Equals to /memory/classes/heap/stacks:bytes.\n# TYPE go_memstats_stack_inuse_bytes gauge\ngo_memstats_stack_inuse_bytes 720896\n# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator. Equals to /memory/classes/heap/stacks:bytes + /memory/classes/os-stacks:bytes.\n# TYPE go_memstats_stack_sys_bytes gauge\ngo_memstats_stack_sys_bytes 720896\n# HELP go_memstats_sys_bytes Number of bytes obtained from system. Equals to /memory/classes/total:byte.\n# TYPE go_memstats_sys_bytes gauge\ngo_memstats_sys_bytes 1.7650952e+07\n# HELP go_sched_gomaxprocs_threads The current runtime.GOMAXPROCS setting, or the number of operating system threads that can execute user-level Go code simultaneously. Sourced from /sched/gomaxprocs:threads\n# TYPE go_sched_gomaxprocs_threads gauge\ngo_sched_gomaxprocs_threads 2\n# HELP go_threads Number of OS threads created.\n# TYPE go_threads gauge\ngo_threads 5\n# HELP kafka_broker_info Information about the Kafka Broker.\n# TYPE kafka_broker_info gauge\nkafka_broker_info{address=\"kafka-poligon-dc1-1.c.bartek-rekke-sandbox.internal:9092\",id=\"11\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc1-2.c.bartek-rekke-sandbox.internal:9092\",id=\"12\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc2-1.c.bartek-rekke-sandbox.internal:9092\",id=\"13\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc2-2.c.bartek-rekke-sandbox.internal:9092\",id=\"14\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc3-1.c.bartek-rekke-sandbox.internal:9092\",id=\"15\"} 1\nkafka_broker_info{address=\"kafka-poligon-dc3-2.c.bartek-rekke-sandbox.internal:9092\",id=\"16\"} 1\n# HELP kafka_brokers Number of Brokers in the Kafka Cluster.\n# TYPE kafka_brokers gauge\nkafka_brokers 6\n# HELP kafka_exporter_build_info A metric with a constant '1' value labeled by version, revision, branch, goversion from which kafka_exporter was built, and the goos and goarch for the build.\n# TYPE kafka_exporter_build_info gauge\nkafka_exporter_build_info{branch=\"HEAD\",goarch=\"amd64\",goos=\"linux\",goversion=\"go1.24.0\",revision=\"8ec24078707d4d3b349e71522ebd7f179746072d\",tags=\"netgo\",version=\"1.9.0\"} 1\n# HELP kafka_topic_partition_current_offset Current Offset of a Broker at Topic/Partition\n# TYPE kafka_topic_partition_current_offset gauge\nkafka_topic_partition_current_offset{partition=\"0\",topic=\"smltest\"} 1\nkafka_topic_partition_current_offset{partition=\"1\",topic=\"smltest\"} 1\nkafka_topic_partition_current_offset{partition=\"2\",topic=\"smltest\"} 0\nkafka_topic_partition_current_offset{partition=\"3\",topic=\"smltest\"} 1\nkafka_topic_partition_current_offset{partition=\"4\",topic=\"smltest\"} 0\nkafka_topic_partition_current_offset{partition=\"5\",topic=\"smltest\"} 0\n# HELP kafka_topic_partition_in_sync_replica Number of In-Sync Replicas for this Topic/Partition\n# TYPE kafka_topic_partition_in_sync_replica gauge\nkafka_topic_partition_in_sync_replica{partition=\"0\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"1\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"2\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"3\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"4\",topic=\"smltest\"} 2\nkafka_topic_partition_in_sync_replica{partition=\"5\",topic=\"smltest\"} 2\n# HELP kafka_topic_partition_leader Leader Broker ID of this Topic/Partition\n# TYPE kafka_topic_partition_leader gauge\nkafka_topic_partition_leader{partition=\"0\",topic=\"smltest\"} 15\nkafka_topic_partition_leader{partition=\"1\",topic=\"smltest\"} 16\nkafka_topic_partition_leader{partition=\"2\",topic=\"smltest\"} 11\nkafka_topic_partition_leader{partition=\"3\",topic=\"smltest\"} 12\nkafka_topic_partition_leader{partition=\"4\",topic=\"smltest\"} 13\nkafka_topic_partition_leader{partition=\"5\",topic=\"smltest\"} 14\n# HELP kafka_topic_partition_leader_is_preferred 1 if Topic/Partition is using the Preferred Broker\n# TYPE kafka_topic_partition_leader_is_preferred gauge\nkafka_topic_partition_leader_is_preferred{partition=\"0\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"1\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"2\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"3\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"4\",topic=\"smltest\"} 1\nkafka_topic_partition_leader_is_preferred{partition=\"5\",topic=\"smltest\"} 1\n# HELP kafka_topic_partition_oldest_offset Oldest Offset of a Broker at Topic/Partition\n# TYPE kafka_topic_partition_oldest_offset gauge\nkafka_topic_partition_oldest_offset{partition=\"0\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"1\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"2\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"3\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"4\",topic=\"smltest\"} 0\nkafka_topic_partition_oldest_offset{partition=\"5\",topic=\"smltest\"} 0\n# HELP kafka_topic_partition_replicas Number of Replicas for this Topic/Partition\n# TYPE kafka_topic_partition_replicas gauge\nkafka_topic_partition_replicas{partition=\"0\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"1\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"2\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"3\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"4\",topic=\"smltest\"} 2\nkafka_topic_partition_replicas{partition=\"5\",topic=\"smltest\"} 2\n# HELP kafka_topic_partition_under_replicated_partition 1 if Topic/Partition is under Replicated\n# TYPE kafka_topic_partition_under_replicated_partition gauge\nkafka_topic_partition_under_replicated_partition{partition=\"0\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"1\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"2\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"3\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"4\",topic=\"smltest\"} 0\nkafka_topic_partition_under_replicated_partition{partition=\"5\",topic=\"smltest\"} 0\n# HELP kafka_topic_partitions Number of partitions for this Topic\n# TYPE kafka_topic_partitions gauge\nkafka_topic_partitions{topic=\"smltest\"} 6\n# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.\n# TYPE process_cpu_seconds_total counter\nprocess_cpu_seconds_total 1.51\n# HELP process_max_fds Maximum number of open file descriptors.\n# TYPE process_max_fds gauge\nprocess_max_fds 524287\n# HELP process_network_receive_bytes_total Number of bytes received by the process over the network.\n# TYPE process_network_receive_bytes_total counter\nprocess_network_receive_bytes_total 2.31658703e+08\n# HELP process_network_transmit_bytes_total Number of bytes sent by the process over the network.\n# TYPE process_network_transmit_bytes_total counter\nprocess_network_transmit_bytes_total 6.045448e+07\n# HELP process_open_fds Number of open file descriptors.\n# TYPE process_open_fds gauge\nprocess_open_fds 11\n# HELP process_resident_memory_bytes Resident memory size in bytes.\n# TYPE process_resident_memory_bytes gauge\nprocess_resident_memory_bytes 2.3236608e+07\n# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.\n# TYPE process_start_time_seconds gauge\nprocess_start_time_seconds 1.75567555438e+09\n# HELP process_virtual_memory_bytes Virtual memory size in bytes.\n# TYPE process_virtual_memory_bytes gauge\nprocess_virtual_memory_bytes 1.273516032e+09\n# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.\n# TYPE process_virtual_memory_max_bytes gauge\nprocess_virtual_memory_max_bytes 1.8446744073709552e+19\n# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.\n# TYPE promhttp_metric_handler_requests_in_flight gauge\npromhttp_metric_handler_requests_in_flight 1\n# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.\n# TYPE promhttp_metric_handler_requests_total counter\npromhttp_metric_handler_requests_total{code=\"200\"} 207\npromhttp_metric_handler_requests_total{code=\"500\"} 0\npromhttp_metric_handler_requests_total{code=\"503\"} 0\n"
  }
}
[2025-08-22 15:55:13.029] 
--- End of Messages ---
[2025-08-22 15:55:13.029] Sending request to LLM API (timeout: 300 seconds)...
[2025-08-22 15:55:34.011] --- LLM Response Received ---
[2025-08-22 15:55:34.011] Number of choices: 1
[2025-08-22 15:55:34.011] Tokens used - Prompt: 14239, Completion: 740, Total: 14979
[2025-08-22 15:55:34.011] 
--- Response Content ---
[2025-08-22 15:55:34.011] Response length: 3553 characters
[2025-08-22 15:55:34.011] Response preview (first 500 chars): Based on the provided configurations and metrics for your Kafka cluster, here are some optimization recommendations focused on improving performance, ensuring reliability, and maintaining a balance between throughput and replica consistency:

### Configuration Review and Recommendations:

1. **Broker ID Configuration:**
   - **Current Issue:** All brokers are configured with the same `broker.id=0`, which will likely cause issues since each broker in a Kafka cluster must have a unique ID.
   - **...
[2025-08-22 15:55:34.011] 
--- Full Response ---
Based on the provided configurations and metrics for your Kafka cluster, here are some optimization recommendations focused on improving performance, ensuring reliability, and maintaining a balance between throughput and replica consistency:

### Configuration Review and Recommendations:

1. **Broker ID Configuration:**
   - **Current Issue:** All brokers are configured with the same `broker.id=0`, which will likely cause issues since each broker in a Kafka cluster must have a unique ID.
   - **Recommendation:** Assign a unique broker ID for each broker. For example, set `broker.id=11` for `broker_11`, `broker.id=12` for `broker_12`, etc.

2. **Replication Factor:**
   - **Current Setting:** `offsets.topic.replication.factor=1` and `transaction.state.log.replication.factor=1`. These should generally be higher to ensure data durability and availability.
   - **Recommendation:** Increase these to at least 3 for better fault tolerance, assuming you have at least that many brokers.

3. **Log Settings:**
   - **Current Setting:** The log retention and segment size are commented out, which means defaults are used.
   - **Recommendation:** Explicitly set `log.segment.bytes` to a reasonable size such as `1 GB` (`1073741824`) to prevent segments from getting too large, which would impact recovery time.
   - Consider reducing `log.retention.hours` if you don't need to keep data for 7 days by default, to save disk space.

4. **Network Threads:**
   - **Current Setting:** `num.network.threads=3` and `num.io.threads=8`.
   - **Recommendation:** Monitor the load on these threads. If you observe bottlenecks in network or I/O operations, consider increasing these numbers. For a busy production environment, `num.network.threads=8` and `num.io.threads=16` can be a good starting point, depending on available CPU resources.

5. **Recovery Threads:**
   - **Recommendation:** If you use RAID configurations for your storage, you can increase `num.recovery.threads.per.data.dir=1` to around 2 or 4 to speed up recovery processes.

6. **Log Flushing Configs:**
   - **Current Setting:** Log flush intervals are commented out.
   - **Recommendation:** Configure these based on your durability and performance requirements. For example, setting `log.flush.interval.messages` to a higher number than the default can improve throughput at the risk of lost messages in a crash.

### Metrics Analysis:

1. **Network Utilization:**
   - The metrics show high numbers for network transmission and reception which suggests significant data flow.
   - **Recommendation:** Ensure data is partitioned properly for optimal distribution. Increase the topic partitions if the network is a bottleneck, allowing for better parallelism. You presently have 6 partitions for `smltest`, which can be matched to the number of brokers for even distribution.

2. **Heap and Memory Usage:**
   - Evaluate JVM heap memory settings (`Xmx` and `Xms`) and ensure they are appropriately configured to handle GC (Garbage Collection) efficiently. Monitor the `Go GC` metrics to assess if there are potential memory shortage or inefficiencies.

3. **ZooKeeper Configuration:**
   - Ensure `zookeeper.connect` has multiple hosts specified if you have more than one ZooKeeper node to avoid single-point failures.
   
By addressing these points, you should see improvements in performance, reliability, and resource utilization across your Kafka cluster. Ensure to perform these changes carefully and monitor the system for any unexpected behavior following configuration updates.
[2025-08-22 15:55:34.011] 
==== END OF REQUEST/RESPONSE ====
[2025-08-22 15:55:34.011] Completed at: 2025-08-22 15:55:34

