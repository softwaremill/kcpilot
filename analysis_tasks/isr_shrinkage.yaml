id: isr_shrinkage
name: ISR Shrinkage Detection
description: Detect partitions with dangerously small ISR sets
category: availability

prompt: |
  Analyze the Kafka cluster for ISR (In-Sync Replica) shrinkage issues.
  
  Admin/Topic Data:
  {admin}
  
  Logs:
  {logs}
  
  Critical Analysis:
  1. Find partitions where ISR count is less than 2 (risky for durability)
     - Especially critical: ISR = 1 with replication factor >= 2
     - This means only ONE broker has current data!
  2. Identify patterns:
     - Is it affecting specific topics?
     - Is it affecting specific brokers?
     - Is it temporary or persistent?
  3. Root cause analysis:
     - Brokers falling behind on replication
     - Network latency between brokers
     - Disk I/O bottlenecks
     - Incorrect replica.lag.time.max.ms setting
     - High producer throughput overwhelming followers
  4. Risk assessment:
     - With acks=all, writes will fail if the single ISR broker fails
     - Data loss risk if the ISR broker crashes
     - Reduced fault tolerance
  
  Look for log patterns:
  - "Shrinking ISR"
  - "Removing replica from ISR"
  - "Replica lag exceeded"
  - "Failed to fetch"
  - "Not caught up"
  
  For each affected partition provide:
  - Topic name and partition ID
  - Current ISR count vs replica count
  - How long it's been in this state
  - Specific broker IDs affected
  
  Format as JSON:
  {
    "findings": [{
      "title": "Critical ISR shrinkage detected",
      "severity": "high",
      "description": "X partitions have ISR < 2",
      "impact": "High risk of data loss with acks=all",
      "affected_partitions": [
        {"topic": "name", "partition": 0, "isr_count": 1, "replica_count": 3, "isr_brokers": [1]}
      ],
      "root_cause": "Identified cause",
      "remediation": "Steps to restore ISR"
    }]
  }

severity_keywords:
  "isr = 1": "critical"
  "single isr": "critical"
  "shrinking isr": "high"
  "isr < 2": "high"
  "reduced isr": "medium"
  "replica lag": "medium"

default_severity: high
enabled: true
